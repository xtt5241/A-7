import torch
from torch.utils.data import Dataset, DataLoader, Subset
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer

# 1ï¸âƒ£ è¯»å– 98 ä¸ªå…³é”®è¯åˆ° 8 ç±»çš„æ˜ å°„
def load_keyword_mapping(mapping_path):
    mapping_df = pd.read_csv(mapping_path, encoding='gbk')

    # ğŸš€ **ç¡®ä¿è·³è¿‡ç¬¬ä¸€è¡Œæ ‡é¢˜**
    if "English Keyword" in mapping_df.iloc[0].values:
        mapping_df = mapping_df.iloc[1:].reset_index(drop=True)

    keyword_to_category = {
        row["English Keyword"].lower().strip(): row["å¯¹åº”çš„ç–¾ç—…ç±»å‹"].strip()
        for _, row in mapping_df.iterrows()
    }
    
    keywords = list(keyword_to_category.keys())  # 98 ä¸ªå…³é”®è¯
    return keyword_to_category, keywords


# 2ï¸âƒ£ è¯»å– Excel è·å–å›¾åƒæ ‡ç­¾ï¼Œå¹¶è½¬æ¢ä¸º 98 å…³é”®è¯æ ¼å¼
def load_labels(excel_path, keyword_to_category):
    df = pd.read_excel(excel_path)
    labels = {}

    for _, row in df.iterrows():
        for eye in ['Left', 'Right']:
            img_name = row[f"{eye}-Fundus"].replace(f"_{eye.lower()}.jpg", ".npy")
            diagnostic_keywords = row[f"{eye}-Diagnostic Keywords"].lower().strip().split(',')

            # è¿‡æ»¤å‡ºåœ¨ mapping é‡Œçš„å…³é”®è¯
            image_keywords = [kw.strip() for kw in diagnostic_keywords if kw.strip() in keyword_to_category]

            # ğŸš€ **é‡è¦ï¼šå¦‚æœæ²¡æœ‰åŒ¹é…çš„å…³é”®è¯ï¼Œä¸è¦åŠ  `other`**
            if not image_keywords:
                image_keywords = []

            labels[img_name] = image_keywords

    return labels

# 3ï¸âƒ£ è‡ªå®šä¹‰æ•°æ®é›†
class EyeDatasetMultiLabel(Dataset):
    def __init__(self, data_dir, excel_path, mapping_path):
        self.data_dir = Path(data_dir)
        self.keyword_to_category, self.keywords_list = load_keyword_mapping(mapping_path)
        self.labels_dict = load_labels(excel_path, self.keyword_to_category)
        self.image_files = list(self.data_dir.glob("*.npy"))

        # ğŸš€ å…³é”®ä¿®æ”¹ï¼š`MultiLabelBinarizer` åªä½¿ç”¨ 98 ä¸ªç±»åˆ«
        self.mlb = MultiLabelBinarizer(classes=self.keywords_list)  
        self.mlb.fit([self.keywords_list])  # è®© `mlb.classes_` è‡ªåŠ¨è·å– 98 ç±»

        print(f"âœ… `data_mul.py` å…³é”®è¯æ•°: {len(self.mlb.classes_)}")  # ğŸš€ æ‰“å°ç±»åˆ«æ•°ï¼Œç¡®ä¿å’Œ `model.py` ä¸€è‡´

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        image_path = self.image_files[idx]
        image = np.load(image_path)
        image = torch.tensor(image, dtype=torch.float32)

        # è·å– 98 å…³é”®è¯æ ‡ç­¾
        image_keywords = self.labels_dict.get(image_path.name, [])
        label = torch.tensor(self.mlb.transform([image_keywords])[0], dtype=torch.float32)

        return image, label

# 4ï¸âƒ£ è®­ç»ƒé›† / éªŒè¯é›†åˆ’åˆ†
excel_path = "dataset\Traning_Dataset.xlsx"
mapping_path = "dataset\English-Chinese_Disease_Mapping.csv"
data_dir = "dataset\output"

dataset = EyeDatasetMultiLabel(data_dir, excel_path, mapping_path)

train_idx, val_idx = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)
train_loader = DataLoader(
    Subset(dataset, train_idx), batch_size=8, shuffle=True, num_workers=0, pin_memory=True
)
val_loader = DataLoader(
    Subset(dataset, val_idx), batch_size=8, shuffle=False, num_workers=0, pin_memory=True
)


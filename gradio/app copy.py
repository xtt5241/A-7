import gradio as gr
import torch
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import requests

###############################################################################
# A) è°ƒç”¨ Ollama çš„æœ¬åœ°æ¥å£
###############################################################################
def call_local_llm(prompt: str) -> str:
    url = "http://127.0.0.1:11434/api/generate"
    payload = {
        "model": "deepseek-r1:1.5b",
        "prompt": prompt,
        "stream": False
    }

    try:
        response = requests.post(url, json=payload, timeout=60)
        response.raise_for_status()
        return response.json()["response"]  # æ·»åŠ è¿™è¡Œè¿”å›æˆåŠŸå“åº”
    except Exception as e:
        print(f"APIè¯·æ±‚å¤±è´¥: {str(e)}")
        return f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼š{str(e)}"



###############################################################################
# B) ç”ŸæˆåŒ»å­¦æŠ¥å‘Š
###############################################################################
def generate_medical_report(disease, confidence):
    # ä¿®æ”¹åçš„ä¸¥æ ¼æ¨¡æ¿ï¼ˆæ·»åŠ åˆ†éš”ç¬¦è¦æ±‚ï¼‰
    prompt = f"""è¯·æ ¹æ®çœ¼åº•æ£€æŸ¥ç»“æœç”ŸæˆåŒ»å­¦æŠ¥å‘Šã€‚æ¨¡æ¿ä¸º
    ## AIåŒ»å­¦æŠ¥å‘Š

    ### æ£€æŸ¥ç»“æœ
    {disease}ï¼ˆç½®ä¿¡åº¦ï¼š{confidence}%ï¼‰

    ### ç—…æƒ…æè¿°

    ### AIå»ºè®®
    
    """
    
    report = call_local_llm(prompt)
    return process_report(report) if report else "æŠ¥å‘Šç”Ÿæˆå¤±è´¥"  # æ·»åŠ ç©ºå€¼æ£€æŸ¥

def process_report(raw_report: str) -> str:
    """é€šè¿‡å›ºå®šåˆ†éš”ç¬¦æˆªå–æ­£å¼æŠ¥å‘Š"""
    delimiter = "## AIåŒ»å­¦æŠ¥å‘Š"
    
    if delimiter in raw_report:
        # æ‰¾åˆ°åˆ†éš”ç¬¦ä½ç½®ï¼ˆä¿ç•™åˆ†éš”ç¬¦ï¼‰
        start_index = raw_report.index(delimiter)
        return raw_report[start_index:]
    
    # ä¿åº•ç­–ç•¥ï¼šè¿”å›åŸå§‹æŠ¥å‘Šï¼ˆç†è®ºä¸Šä¸ä¼šè§¦å‘ï¼‰
    return raw_report


###############################################################################
# 1) å ä½æ¨¡å‹ & ç±»åˆ«æ ‡ç­¾
###############################################################################
model = None
CLASSES = [
    "ç±»ç¤ºä¾‹1", "ç±»ç¤ºä¾‹2", "ç±»ç¤ºä¾‹3", 
    "ç±»ç¤ºä¾‹4", "ç±»ç¤ºä¾‹5", "ç±»ç¤ºä¾‹6",
    "ç±»ç¤ºä¾‹7", "ç±»ç¤ºä¾‹8"
]

###############################################################################
# 2) å›¾åƒé¢„å¤„ç†
###############################################################################
def preprocess_image(image_left, image_right):
    transform = transforms.Compose([
        transforms.Resize((456, 456)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std =[0.229, 0.224, 0.225])
    ])

    if isinstance(image_left, np.ndarray):
        image_left = Image.fromarray(image_left)
    if isinstance(image_right, np.ndarray):
        image_right = Image.fromarray(image_right)

    image_left  = transform(image_left)
    image_right = transform(image_right)

    merged_image = torch.cat((image_left, image_right), dim=0)
    return merged_image.unsqueeze(0)


###############################################################################
# 3) é¢„æµ‹å¹¶ç”ŸæˆåŒ»å­¦æŠ¥å‘Š
###############################################################################
def predict(image_left, image_right):
    input_tensor = preprocess_image(image_left, image_right)

    # -----------------------------
    # TODO: è¿™é‡Œæ›¿æ¢ä¸ºçœŸå®çš„æ¨¡å‹æ¨ç†è¿‡ç¨‹
    # -----------------------------
    detected_diseases = ["ç³–å°¿ç—…è§†ç½‘è†œç—…å˜", "é’å…‰çœ¼"]
    if not detected_diseases:
        detected_diseases = ["æœªæ£€æµ‹åˆ°ç–¾ç—…"]

    disease_str = ", ".join(detected_diseases)
    medical_report = generate_medical_report(disease_str, 92)
    return disease_str, medical_report  # ç›´æ¥è¿”å›åŸå§‹æŠ¥å‘Šå†…å®¹


###############################################################################
# 4) ä½¿ç”¨ Blocks ä¼˜åŒ–ç•Œé¢å¸ƒå±€å¹¶è‡ªå®šä¹‰æ ·å¼
###############################################################################
custom_css = """
/* ä¼˜åŒ–åçš„ CSS */
/* æ ‡é¢˜æ ·å¼ */
#title {
  text-align: center;
  font-size: 2.5em;
  margin: 0.5em auto;
  color: #2B5876;
  font-weight: 600;
  letter-spacing: 1px;
}

/* å‰¯æ ‡é¢˜æ ·å¼ */
#subtitle {
  text-align: center;
  font-size: 1em;
  color: #666;
  margin: 0 auto 2em;
  max-width: 80%;
  line-height: 1.5;
}

/* å¸ƒå±€ä¼˜åŒ– */
.row {
  gap: 1rem !important;  /* å‡å°‘åˆ—é—´è· */
}

/* å›¾åƒå®¹å™¨æ ·å¼ */
.my-img {
  width: 300px;
  height: 300px;
  border: 3px solid #f0f0f0;
  border-radius: 10px;
  box-shadow: 0 2px 8px rgba(0,0,0,0.1);
}

/* æ£€æµ‹æŒ‰é’®ä¼˜åŒ– */
#detect-button {
  width: 150px;        
  margin: 1.5rem 0 0; /* ç§»é™¤å·¦å³ margin */
  background: linear-gradient(45deg, #2B5876, #4e4376);
  color: white !important;
  font-weight: bold;
  transition: all 0.3s;
}

/* è°ƒæ•´æŠ¥å‘Šæ¡†æ ·å¼ */
#report-box {
  height: 65vh;           /* ä½¿ç”¨è§†çª—é«˜åº¦å•ä½ */
  max-height: 700px;      /* æœ€å¤§é«˜åº¦é™åˆ¶ */
  padding: 1.2rem;
  border: 2px solid #e0e0e0;
  border-radius: 8px;
  overflow-y: scroll !important;  /* å¼ºåˆ¶æ˜¾ç¤ºæ»šåŠ¨æ¡ */
  scrollbar-width: thin;  /* æ›´ç»†çš„æ»šåŠ¨æ¡ */
}

/* ä¼˜åŒ–æ»šåŠ¨æ¡æ ·å¼ */
#report-box::-webkit-scrollbar {
  width: 8px;
}

#report-box::-webkit-scrollbar-track {
  background: #f1f1f1; 
}

#report-box::-webkit-scrollbar-thumb {
  background: #888; 
  border-radius: 4px;
}

#report-box::-webkit-scrollbar-thumb:hover {
  background: #555; 
}

/* ä¼˜åŒ–Markdownæ˜¾ç¤º */
#report-box h3, #report-box h4 {
  color: #2B5876 !important;
  margin-top: 1em !important;
}

#report-box ul {
  padding-left: 1.5em;
  margin: 0.8em 0;
}

#report-box li {
  margin: 0.5em 0;
}
"""

with gr.Blocks(css=custom_css) as demo:
    # æ ‡é¢˜ä¸å‰¯æ ‡é¢˜ï¼ˆå·²å±…ä¸­ï¼‰
    gr.Markdown("<p id='title'>ğŸ‘ï¸ AI çœ¼åº•æ£€æµ‹ç³»ç»Ÿ</p>")
    gr.Markdown(
        "<p id='subtitle'>æœ¬ç³»ç»ŸåŸºäºæ·±åº¦å­¦ä¹ æ¨¡å‹åˆ†æå·¦å³çœ¼çœ¼åº•å›¾åƒï¼Œé€šè¿‡æœ¬åœ°éƒ¨ç½²çš„ deepseek-r1:1.5b å¤§æ¨¡å‹ç”ŸæˆåŒ»å­¦æŠ¥å‘Š<br>"
        "<em style='color: #e74c3c; font-size: 0.9em;'>æ£€æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼Œå®é™…è¯Šæ–­è¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ</em></p>"
    )

    # ç´§å‡‘å¸ƒå±€
    with gr.Row(equal_height=True):
        # å·¦ä¾§è¾“å…¥åŒº
        with gr.Column(scale=1, min_width=340):
            left_eye_input = gr.Image(type="numpy", label="å·¦çœ¼å›¾åƒ", elem_classes="my-img")
            right_eye_input = gr.Image(type="numpy", label="å³çœ¼å›¾åƒ", elem_classes="my-img")
            with gr.Row(elem_classes="button-container"):  # æ–°å¢å®¹å™¨
                detect_button = gr.Button("å¼€å§‹æ£€æµ‹", elem_id="detect-button")

        # å³ä¾§è¾“å‡ºåŒº
        with gr.Column(scale=2, min_width=500):
            disease_output = gr.Textbox(label="æ£€æµ‹ç»“æœ", interactive=False, elem_id="disease-box")
            with gr.Group():
                gr.Markdown("")
                report_output = gr.Markdown(
                    elem_id="report-box",
                    value="ç­‰å¾…ç”ŸæˆæŠ¥å‘Š...",
                )

    # ä¿®æ”¹ç‚¹å‡»äº‹ä»¶è¿”å›å€¼
    detect_button.click(
        fn=predict,
        inputs=[left_eye_input, right_eye_input],
        outputs=[disease_output, report_output]
    )

if __name__ == "__main__":
    demo.launch()
